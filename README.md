# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

The dataset analysed in this project contains data about potential customers of a bank. We seek to predict whether those people could be converted into actual customers that subscribed to a fixed term deposit.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

The best performing model was a "Voting Ensemble" chosen by Azure Automated ML with an accuracy of nearly 92%. However, it outperformed a simple logistic regression with hyperparameters tuned using HyperDrive only barely.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

For the Scikit-lean pipeline the retrieval of data was actually done within the training script. A logistic regression had been chosen as classification algorithm. The training script was submitted to be run as a HyperDrive run to find optimal values for the maximum number of iterations and regularization strength of the logistic regression.

**What are the benefits of the parameter sampler you chose?**

A random parameter sampler makes sure that you do not make (possibly wrong) pre-assumptions on best parameters. It makes sure that all values have the same chance of being tried out. For the regularization I chose a loguniform distribution to increase the chance of small values being drawn. This is because I assumed that the difference between a regularization of 0 and 1 has a larger impact than the difference between a regularization of 499 and 500.

**What are the benefits of the early stopping policy you chose?**

The bandit stopping policy terminates any runs where the primary metric is not within the specified slack factor/slack amount relative to the best performing training run. Thus it makes sure that we are not wasting time and cost on parameter combinations that are not likely to work well.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

For the "Voting Ensemble" chosen by Azure Automated ML the most important hyper parameters are the algorithms used in the ensemble and their weight. Azure Automated ML a mixture of `SparseNormalizer` or `MaxAbsScaler` for data transformation and different classification algorithms like `XGBoostClassifier` or `Logistic Regression`.


## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

Actually both approaches lead to very similar results in terms of accuracy. The AutoML model reached an accuracy of 0.91621 and the best model from the HyperDrive run had an accuracy of 0.90910. Personally I would prefer the LogisticRegression from the HyperDrive run because it is easier to explain to stakeholders then an ensemble model.

However, the Auto ML model could be delivered with a lot less effort and it is possible to restrict it to models that we are sure our stakeholders would trust.


## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

The AutoML data guardlines show an alert that classes are highly imbalanced (much more unsuccessful calls then successful one, of course). This might be an area for improvements.

The AutoML run includes and explanation of the model which shows that the most decisive feature was the duration of a call. It is not really surprising that this is highly correlated with the conversion rate but I doubt that this is very helpful for the business. I would try to remove all features that we do not know **before** we call a potential customer.

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**

I worked on this project using my own Azure subscription.
